{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBBHEKZ5Java",
        "outputId": "4083f1ba-fde1-490b-90d5-6c63260b9304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigrams:\n",
            "('Natural', 'language', 'processing')\n",
            "('language', 'processing', '(')\n",
            "('processing', '(', 'NLP')\n",
            "('(', 'NLP', ')')\n",
            "('NLP', ')', 'is')\n",
            "(')', 'is', 'a')\n",
            "('is', 'a', 'subfield')\n",
            "('a', 'subfield', 'of')\n",
            "('subfield', 'of', 'linguistics')\n",
            "('of', 'linguistics', ',')\n",
            "('linguistics', ',', 'computer')\n",
            "(',', 'computer', 'science')\n",
            "('computer', 'science', ',')\n",
            "('science', ',', 'and')\n",
            "(',', 'and', 'artificial')\n",
            "('and', 'artificial', 'intelligence')\n",
            "('artificial', 'intelligence', 'concerned')\n",
            "('intelligence', 'concerned', 'with')\n",
            "('concerned', 'with', 'the')\n",
            "('with', 'the', 'interactions')\n",
            "('the', 'interactions', 'between')\n",
            "('interactions', 'between', 'computers')\n",
            "('between', 'computers', 'and')\n",
            "('computers', 'and', 'human')\n",
            "('and', 'human', 'language')\n",
            "('human', 'language', ',')\n",
            "('language', ',', 'in')\n",
            "(',', 'in', 'particular')\n",
            "('in', 'particular', 'how')\n",
            "('particular', 'how', 'to')\n",
            "('how', 'to', 'program')\n",
            "('to', 'program', 'computers')\n",
            "('program', 'computers', 'to')\n",
            "('computers', 'to', 'process')\n",
            "('to', 'process', 'and')\n",
            "('process', 'and', 'analyze')\n",
            "('and', 'analyze', 'large')\n",
            "('analyze', 'large', 'amounts')\n",
            "('large', 'amounts', 'of')\n",
            "('amounts', 'of', 'natural')\n",
            "('of', 'natural', 'language')\n",
            "('natural', 'language', 'data')\n",
            "('language', 'data', '.')\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, trigrams\n",
        "\n",
        "# Ensure necessary NLTK data is downloaded\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Sample text corpus\n",
        "text = \"\"\"\n",
        "Natural language processing (NLP) is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data.\n",
        "\"\"\"\n",
        "\n",
        "# Tokenize the text into words\n",
        "tokens = word_tokenize(text)\n",
        "\n",
        "# Generate trigrams\n",
        "trigrams_list = list(trigrams(tokens))\n",
        "\n",
        "# Print trigrams\n",
        "print(\"Trigrams:\")\n",
        "for trigram in trigrams_list:\n",
        "    print(trigram)\n"
      ]
    }
  ]
}